---
title: "p8105_hw6_jl6048"
author: Jinghan Liu
output: github_document
---


```{r message=FALSE}
library(tidyverse)
library(readxl)
library(modelr)

knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "90%")
```


### Problem 1

Load and clean the dataset for regression analysis:

```{r}
child_df = 
  readr::read_csv("data/birthweight.csv") %>%
  janitor::clean_names() %>%
  mutate(
    babysex = as.factor(babysex),
    frace = as.factor(frace),
    mrace = as.factor(mrace),
    malform = as.factor(malform),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = fct_recode(frace, "white" = "1", "black" = "2", "asian" = "3", "puerto rican" = "4", "other" = "8", "unknown" = "9"),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", "asian" = "3","puerto rican" = "4", "other" = "8", "unknown" = "9"))

# check for missing value - no missing
sum(complete.cases(child_df))
sum(!complete.cases(child_df))
```


Propose a regression model for birthweight:
```{r}
model_1 = lm(bwt ~ gaweeks, data = child_df)
summary(model_1)
```


 A plot of model residuals against fitted values:
```{r}
child_df %>% 
  modelr::add_residuals(model_1) %>% 
  modelr::add_predictions(model_1) %>% 
  ggplot(aes(x = pred, y = resid, color = resid)) + 
  geom_point(alpha = 0.5)+ 
  stat_smooth(method = "lm") +
  labs(title = "Predicted vs residuals", 
       x = "Predicted", 
       y = "Residuals")
```

**Describe:**
model_1 is a simple linear regression with gestational age as the predictor (X) and birth weight as Y. It can be seen from the plot that the residuals are relatively evenly distributed around y = 0 and below. Therefore, it satisfies the linearity assumption.


Compare your model to two others:

```{r}
# One using length at birth and gestational age as predictors (main effects only)
model_2 = lm(bwt ~ blength + gaweeks, data = child_df)
summary(model_2) %>% 
  broom::tidy()


#One using head circumference, length, sex, and all interactions (including the three-way interaction) between these
model_3 = lm(bwt ~bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex , data = child_df) 
summary(model_3) %>% 
  broom::tidy()
```

Make this comparison in terms of the cross-validated prediction error:

```{r}
cv_data =
  crossv_mc(child_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))
```


```{r}
cv_data = 
  cv_data %>% 
  mutate(
    model_1  = map(train, ~lm(bwt ~ gaweeks, data = .x)),
    model_2  = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3  = map(train, ~lm(bwt ~ 
       bhead + blength + babysex + 
       bhead * blength + 
       bhead * babysex + 
       blength * babysex + 
       bhead * blength * babysex, data = .x))) %>% 
  mutate(
    rmse_model_1 = 
      map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2 = 
      map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_model_3 =
      map2_dbl(model_3, test, ~rmse(model = .x, data = .y)))
```


```{r}
cv_data %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin() +
   labs(
        title = "Comparing birthweight models",
        x = "Model",
        y = "Rmse"
      )
```

**Comment:**
From this violin plot, it can be seen that the Rmse of the first model is the highest, and the Rmse of the third model is the lowest. The third model with interaction terms is the best model because it has the lowest mean square value.


### Problem 2:
Load data
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
weather_df 
```

 For R squared: 
```{r}
bootstrap_r =
  weather_df %>% 
  modelr::bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm( tmax ~ tmin , data = .x) ),
    results = map(models, broom::glance)) %>% 
  select(.id, results) %>% 
  unnest(results)
bootstrap_r

bootstrap_r %>% 
ggplot(aes(x = r.squared)) + 
  geom_density() +
   labs(
      x = "R squared values",
      y = "Density",
      title = "Distribution of R Squared Estimates")

```

For log of betas:
```{r}
bootstrap_log =
  weather_df %>% 
   modelr::bootstrap(n = 5000)%>% 
  mutate(
    models = map(strap, ~lm( tmax ~ tmin , data = .x) ),
    results = map(models, broom::tidy)) %>% 
  select(.id, results) %>% 
  unnest(results)%>% 
  select(.id, term, estimate) %>% 
  pivot_wider(
    names_from = term,
    values_from = estimate
  ) %>% 
  janitor::clean_names() %>% 
  mutate(
    beta_log = log(intercept * tmin)
  ) 
bootstrap_log

bootstrap_log %>% 
ggplot(aes(x = beta_log)) + 
  geom_density() +
   labs(
      x = "Log coefficients values",
      y = "Density",
      title = "Distribution of log coefficients Estimates")

```
**Comment:**
From the distribution plot, we can easily find that the distribution of R Squared looks like a normal distribution but slightly left skewed. The log plot looks like more skewed to the normal distribution than R. R squared  with a mean of `r round(mean(pull(bootstrap_r, r.squared)), 3)` and standard deviation of `r round(sd(pull(bootstrap_r, r.squared)), 3)`. 
Log estimates with a mean of `r round(mean(pull(bootstrap_log, beta_log)), 3)` and standard deviation of `r round(sd(pull(bootstrap_log, beta_log)), 3)`.



Confidence Interval :

```{r}
bootstrap_r %>% 
  summarize(
    CI_lower_r = quantile(r.squared, 0.025),
    CI_upper_r = quantile(r.squared, 0.975)
  ) %>% 
  knitr::kable(digits = 3)

bootstrap_log %>% 
  summarize(
    CI_lower_log = quantile(beta_log, 0.025),
    CI_upper_log = quantile(beta_log, 0.975)
  ) %>% 
  knitr::kable(digits = 3)

```

